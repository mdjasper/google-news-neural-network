<!DOCTYPE html>
<html>
<head>
	<title>News Neural Network</title>
	<link rel="stylesheet" type="text/css" href="static/site.css">
</head>
<body>
<header>
<div class="page-width">
	<h2 class="page-title">News Neural Network</h2>
	<ul class="nav">
		<li><a href="/">Home</a></li>
		<li><a href="/about">About</a></li>
		<li><a href="/source">Source</a></li>
	</ul>
	</div>
</header>
<main>
	<section class="hero">
	<div class="page-width">
		<h1 class="hero__heading">Using historical news and stock data to predict future changes.</h1>
		</div>
	</section>
	<section class="about">
	<div class="page-width">
		<h2 class="section__title">How this project works</h2>
		<p>A dataset was build containing news headlines and summaries of the <a href="http://portfolios.morningstar.com/fund/holdings?t=SPY">top 10 holdings of the S&amp;P 500</a> ticker symbols from Google News ranging from 1 Jan 2015 to 31 Oct 2015, as well as stock price changes for these symbols and dates. This dataset contains nearly 2700 day/symbol records &mdash; or 567,912 words.</p>
		<div class="code">
		<h3 class="code__title">Corpus Sample</h3>
		<pre>
"-K-LDX-ahbYGeGA8QIID" : {
	"bodies" : [ "No companies have done this better over the past decade than JPMorgan Chase (NYSE:JPM) and Wells Fargo (NYSE:WFC). The chart below illustrates thisÂ ...", ...],
	"date" : "7/30/2015",
	"headlines" : [ "Buy Bank Stocks Like a Boss", ...],
	"symbol" : "WFC"
}</pre>
		</div>
		<p>Using a <a href="http://www.vikparuchuri.com/blog/natural-language-processing-tutorial/#bag-of-words-model">Bag-of-words</a> NLP model, features were extracted from the data, and a data-set created of text features and price changes for each stock &amp; date.</p>
		<p>A neural network was created using <a href="http://pybrain.org/docs/index.html">PyBrain</a> and trained on a sample from this data set.</p>
		<div class="code">
			<h3 class="code__title">Vectorized Data Sample</h3>
			<pre>
{
	"input":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,1,0,1,1,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,0,0,1,0,0,1,1,0,0,1,1,0,1,1,0,1,0,1,0,0,1,0,1,1,0,1,1,0,1,1,1],
	"output":{"direction":0}
}</pre>
		</div>
		</div>
	</section>
	<section class="results">
		<div class="page-width">
			<h2 class="section__title">Results</h2>
		<p>Using the remaining data (not trained), the neural network has been tested and achieved results up to 80% accuracy.</p>
		<figure>
		<h3 class="figure__title">Prediction distribution</h3>
		<img src="images/distribution.png" alt="prediction distribution showing 80% accuracy"/>
		<figcaption>
			Blue series represents negative predictions, centered around 0.1. Red series represents positive predictions centered around 1.
		</figcaption>	
		</figure>
		
		</div>
	</section>
	<section class="technology">
	<div class="page-width">
		<h2 class="section__title">Technology Used</h2>
		
		<p><a href="https://nodejs.org/en/">Node.js</a> is used to run a web-scraper with asynchronous web requests to fetch the news data from Google News and save it to Firebase (database). It is also used to extract features from the corpus, and create a Bag-of-Words data-set based on the features.</p>
		
		<p><a href="https://github.com/NaturalNode/natural">Natural</a> is a Natural Language Processing toolkit for Node.js. It is used to tokenize and stem the corpus.</p>
		
		<p><a href="https://www.python.org/">Python</a> is used to create and train a neural network model using and random sample of < 50% of the data-set.</p>
		
		<p><a href="http://pybrain.org/">PyBrain</a> is a Machine Learning framework that is used to create a train the prediction neural network</p>
		</div>
	</section>
	<section class="project">
		<div class="page-width">
			<h2 class="section__title">Project Information</h2>
			<p>This project was created by Michael Jasper as course-work for CS 6900 at Utah State University.</p>
			<p>This page was last updated on 23 Nov 2015.</p>
		</div>
	</section>
</main>
</body>
</html>
